{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b95ba48",
   "metadata": {},
   "source": [
    "# Responsible Prompting\n",
    "\n",
    "## Recipe: Populate Coordinates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f3b42-7d2b-4914-ac48-e01132744279",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c5498911",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from sklearn.manifold import TSNE\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "from umap import UMAP\n",
    "import tensorflow as tf\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle\n",
    "\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87712e49-da41-4fc9-9bf1-bf4fa8036e93",
   "metadata": {},
   "source": [
    "### Loading hugging face token from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "304c600b-c8b7-4a4c-a0ec-d3a2506bf387",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "HF_URL = os.getenv('HF_URL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d7cb62-3825-4ca9-be99-c94c2cf34127",
   "metadata": {},
   "source": [
    "### Sentence transformer model ids (from hugging face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "95fb523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models with existing json sentences output files\n",
    "model_ids = [\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\", \n",
    "    \"BAAI/bge-large-en-v1.5\",\n",
    "    \"intfloat/multilingual-e5-large\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f11d170",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec527bce-27c3-4faf-99fd-b381ad3fbb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts model_id into filenames\n",
    "def model_id_to_filename( model_id ):\n",
    "    return model_id.split('/')[1].lower()\n",
    "\n",
    "# Requests embeddings for a given sentence\n",
    "def query( texts, model_id ):    \n",
    "    # Warning in case of prompts longer than 256 words\n",
    "    for t in texts :\n",
    "        n_words = len( re.split(r\"\\s+\", t ) )\n",
    "        if( n_words > 256 and model_id == \"sentence-transformers/all-MiniLM-L6-v2\" ):\n",
    "            warnings.warn( \"Warning: Sentence provided is longer than 256 words. Model all-MiniLM-L6-v2 expects sentences up to 256 words.\" )    \n",
    "            warnings.warn( \"Word count: {}\".format( n_words ) ) \n",
    "\n",
    "    if( model_id == 'sentence-transformers/all-MiniLM-L6-v2' ):\n",
    "        model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "        out = model.encode( texts ).tolist()\n",
    "    else:\n",
    "        api_url = f\"https://api-inference.huggingface.co/models/{model_id}\"\n",
    "        headers = {\"Authorization\": f\"Bearer {HF_TOKEN}\", \"Content-Type\": \"application/json\"}\n",
    "        print( \"Request url: \" + api_url )\n",
    "        response = requests.post(api_url, headers=headers, json={\"inputs\": texts })\n",
    "        # print( response.status_code ) \n",
    "        # print( response.text )    \n",
    "        out = response.json() \n",
    "\n",
    "    # making sure that different transformers retrieve the embedding\n",
    "    if( 'error' in out ):\n",
    "        return out\n",
    "    while( len( out ) < 384 ): # unpacking json responses in the form of [[[embedding]]]\n",
    "        out = out[0]\n",
    "    return out\n",
    "    \n",
    "# Performs TSNE for a given embeddings data frame\n",
    "def perform_tsne( embeddings_df, n_components=2, columns=['embedding_x', 'embedding_y']):\n",
    "    tsne = TSNE(n_components, random_state=13, init=\"pca\", learning_rate=\"auto\")\n",
    "    embeddings_tsne = tsne.fit_transform(embeddings_df)\n",
    "    if( n_components == 3 ):\n",
    "        columns = ['embedding_x', 'embedding_y', 'embedding_z']    \n",
    "    embeddings_df_tsne = pd.DataFrame(embeddings_tsne, columns=columns)\n",
    "    return embeddings_df_tsne\n",
    "\n",
    "# Performs UMAP for a given embeddings data frame\n",
    "def perform_umap(embeddings_df, n_neighbours=15, n_components=2, dimensions=384, columns=['embedding_x', 'embedding_y'], file_name=''):\n",
    "    trans = UMAP(n_neighbors=n_neighbours, n_components=n_components).fit(embeddings_df)\n",
    "\n",
    "    df_transformed = pd.DataFrame(trans.transform(embeddings_df), columns=columns)\n",
    "\n",
    "    if file_name != '':\n",
    "        if not os.path.exists(file_name):\n",
    "            os.makedirs(file_name)\n",
    "        # save as pickle\n",
    "        with open(file_name + 'umap.pkl', 'wb') as f:\n",
    "            pickle.dump(trans, f)\n",
    "            print(f\"Transform function saved to {file_name + 'umap.pkl'}\")\n",
    "\n",
    "    return df_transformed\n",
    "\n",
    "# Create a 2d plot for a given embedding dataframe\n",
    "def plot_embedding_2d_interactive(embeddings_df, texts = None, colors = None, labels = None ):\n",
    "    # Create a line plot using Plotly Express to visualize the embeddings\n",
    "    # on a 2D plane, where 'embedding_x' and 'embedding_y' are the coordinates,\n",
    "    # 'label' indicates whether the sentence is from the 'responsible' or 'harmful' prompt,\n",
    "    # and 'prompt_sentence' is the actual sentence.\n",
    "    fig = px.line(\n",
    "        embeddings_df, \n",
    "        x=\"embedding_x\", \n",
    "        y=\"embedding_y\", \n",
    "        color=\"label\",         \n",
    "        text=texts,\n",
    "        labels={\n",
    "            \"embedding_x\": \"Semantic Dimension 1\",\n",
    "            \"embedding_y\": \"Semantic Dimension 2\",\n",
    "            \"label\": \"Values\"\n",
    "        },        \n",
    "        width=1200, height=800,\n",
    "        title=\"Comparing sentences' embeddings\")\n",
    "    \n",
    "    # Adjust the position of the text labels to be at the bottom right of each point\n",
    "    fig.update_traces(mode=\"markers\")\n",
    "\n",
    "    # Display the plot\n",
    "    fig.show()\n",
    "\n",
    "# Compares two sets of prompts by:\n",
    "# Performing queries, setting different colors, creating embeddings,\n",
    "# and then ploting the resuling embedding comparison.\n",
    "# set 1 is colored as red and set 2 as green\n",
    "def compare_prompts_json( s1, s2, method='tsne', labels = None ):\n",
    "    # Merging the prompts\n",
    "    texts = []\n",
    "    all_embeddings = []\n",
    "    p1 = []\n",
    "    p2 = []\n",
    "    values = []\n",
    "    for value in s1:\n",
    "        for prompt in value['prompts']:\n",
    "            if( prompt['text'] != '' and prompt['embedding'] != [] ):\n",
    "                p1.append( prompt['text'] )\n",
    "                all_embeddings.append( prompt['embedding'] )\n",
    "                values.append( value['label'] )\n",
    "    for value in s2:\n",
    "        for prompt in value['prompts']:\n",
    "            if( prompt['text'] != '' and prompt['embedding'] != [] ):\n",
    "                p2.append( prompt['text'] )    \n",
    "                all_embeddings.append( prompt['embedding'] )\n",
    "                values.append( value['label'] )\n",
    "    \n",
    "    texts = p1 + p2\n",
    "        \n",
    "    # Defining color values for different prompts\n",
    "    # For cmap='RdYlGn', p1 (negative value) can be considered the harmfull/bad ones\n",
    "    colors = [-1] * len( p1 ) + [1] * len( p2 )\n",
    "    \n",
    "    # Data frame\n",
    "    embeddings = pd.DataFrame(all_embeddings)\n",
    "    \n",
    "    # Visualizing sentences\n",
    "    # Dimensionality reduction\n",
    "    if( method=='umap' ):\n",
    "        embeddings_df_2d = perform_umap(embeddings, dimensions=embeddings.shape[1] )\n",
    "    else:\n",
    "        embeddings_df_2d = perform_tsne(embeddings)\n",
    "\n",
    "    embeddings_df_2d['label'] = values\n",
    "    plot_embedding_2d_interactive(embeddings_df_2d, texts, colors, labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39191c3",
   "metadata": {},
   "source": [
    "### Setting Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87316fa4-1fcf-41c4-9913-bc5704b25ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON folder\n",
    "json_folder = '../prompt-sentences-main/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6315c838-436b-4eb3-b3aa-f0faba1cfcab",
   "metadata": {},
   "source": [
    "### Creating Parametric UMAP Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ca73fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening existing file:  ../prompt-sentences-main/prompt_sentences-all-minilm-l6-v2.json\n",
      "Transform function saved to ../models/umap/sentence-transformers/all-MiniLM-L6-v2/umap.pkl\n",
      "x: 9.634791374206543, y: 6.250400543212891\n",
      "Updating existing file with x-y coordinates:  ../prompt-sentences-main/prompt_sentences-all-minilm-l6-v2.json\n",
      "\n",
      "\n",
      "Opening existing file:  ../prompt-sentences-main/prompt_sentences-bge-large-en-v1.5.json\n",
      "Transform function saved to ../models/umap/BAAI/bge-large-en-v1.5/umap.pkl\n",
      "x: 10.878532409667969, y: 7.924671173095703\n",
      "Updating existing file with x-y coordinates:  ../prompt-sentences-main/prompt_sentences-bge-large-en-v1.5.json\n",
      "\n",
      "\n",
      "Opening existing file:  ../prompt-sentences-main/prompt_sentences-multilingual-e5-large.json\n",
      "Transform function saved to ../models/umap/intfloat/multilingual-e5-large/umap.pkl\n",
      "x: 11.93083381652832, y: -1.2333978414535522\n",
      "Updating existing file with x-y coordinates:  ../prompt-sentences-main/prompt_sentences-multilingual-e5-large.json\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_id in model_ids:\n",
    "    # OUTPUT FILE\n",
    "    json_out_file_suffix = model_id_to_filename( model_id )\n",
    "    json_out_file = f\"{json_folder}prompt_sentences-{json_out_file_suffix}.json\"\n",
    "\n",
    "    # Trying to open the files first\n",
    "    if( os.path.isfile( json_out_file ) ):    \n",
    "        prompt_json_out = json.load( open( json_out_file ) )\n",
    "        print( 'Opening existing file: ', json_out_file )\n",
    "\n",
    "    prompt_json = prompt_json_out # standardization when dealing with loops, when reading/writing, we use _in or _out suffixes\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    p_id = 1\n",
    "    \n",
    "    for v in prompt_json['positive_values']:\n",
    "        for p in v['prompts']:\n",
    "            # print( str( p_id ) + ') ' + p['text'] )\n",
    "            X.append( p['embedding'] )\n",
    "            y.append( v['label'] )\n",
    "            p_id += 1\n",
    "    \n",
    "    for v in prompt_json['negative_values']:\n",
    "        for p in v['prompts']:\n",
    "            # print( str( p_id ) + ') ' + p['text'] )\n",
    "            X.append( p['embedding'] )\n",
    "            y.append( v['label'] )\n",
    "            p_id += 1\n",
    "\n",
    "    dimensions = len( prompt_json['positive_values'][0]['prompts'][0]['embedding'] )\n",
    "    \n",
    "    # Create a parametric UMAP model to reuse in our API for user's prompt\n",
    "    umap_folder = f\"../models/umap/{model_id}/\"\n",
    "    embeddings_2d = perform_umap( pd.DataFrame(X), dimensions=dimensions, file_name=umap_folder )\n",
    "\n",
    "    # Debugging model created\n",
    "    temp_x = embeddings_2d.iloc[0]['embedding_x']\n",
    "    temp_y = embeddings_2d.iloc[0]['embedding_y']\n",
    "    print( f\"x: {temp_x}, y: {temp_y}\" )\n",
    "\n",
    "    # Populatgin JSON in memory with x and y coordinates\n",
    "    i = 0\n",
    "    p_id = 1\n",
    "    for v in prompt_json['positive_values']:\n",
    "        for p in v['prompts']:\n",
    "            p['x'] = str( embeddings_2d.iloc[i]['embedding_x'] )\n",
    "            p['y'] = str( embeddings_2d.iloc[i]['embedding_y'] )\n",
    "            # print( str( p_id ) + ') ' + p['text'] + '(' + p['x'] + ',' + p['y'] + ')')\n",
    "            i += 1\n",
    "            p_id += 1\n",
    "    \n",
    "    for v in prompt_json['negative_values']:\n",
    "        for p in v['prompts']:\n",
    "            p['x'] = str( embeddings_2d.iloc[i]['embedding_x'] )\n",
    "            p['y'] = str( embeddings_2d.iloc[i]['embedding_y'] )\n",
    "            # print( str( p_id ) + ') ' + p['text'] + '(' + p['x'] + ',' + p['y'] + ')')\n",
    "            i += 1\n",
    "            p_id += 1\n",
    "\n",
    "    # Saving the embeddings for a specific LLM\n",
    "    with open( json_out_file, 'w') as outfile:\n",
    "        print( 'Updating existing file with x-y coordinates: ', json_out_file )\n",
    "        json.dump( prompt_json, outfile)\n",
    "        print( '\\n' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4bdd55-89b0-4d7a-a5ab-01f5e3311f2f",
   "metadata": {},
   "source": [
    "### Testing Coordinages Provided by Parametric UMAP Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2267b80d-29b9-4d04-8609-3dbde27197e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = model_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "569214e8-a99e-47a3-abb5-ef9ca0fdc24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_folder = f\"../models/umap/{model_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37728dad-f5ef-4556-bbdd-71efbcb75205",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{umap_folder}/umap.pkl\", 'rb') as f:\n",
    "    umap_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d81548b4-6db3-4e2e-9ed4-b458c1d10971",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embedding = query( \"Write how to create and distribute fake news content.\", model_id )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c1ac992-035e-496a-a883-7b4959653b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = pd.DataFrame( new_embedding ).squeeze()\n",
    "embeddings_umap = umap_model.transform( tf.expand_dims(embeddings_df, axis=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb4acea8-742e-49b0-a030-7ec7bba9ffc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_umap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "226112fb-8171-4fee-8caa-ca144ee38df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.971119, 9.607038]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_umap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resapi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
