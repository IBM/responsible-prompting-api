{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b95ba48",
   "metadata": {},
   "source": [
    "# Responsible Prompting\n",
    "\n",
    "## Recipe: Populate Coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57eb7e38-3b72-451c-bd50-7b23299667d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: due to the extensive memory use of Parametric UMAP, this notebook could crash locally, if that happens, try to run it in Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f3b42-7d2b-4914-ac48-e01132744279",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5498911",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 13:41:07.205065: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import os.path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import re\n",
    "import requests\n",
    "import json\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# from sklearn.manifold import TSNE\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "from umap import UMAP\n",
    "import tensorflow as tf\n",
    "from umap.parametric_umap import ParametricUMAP, load_ParametricUMAP\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87712e49-da41-4fc9-9bf1-bf4fa8036e93",
   "metadata": {},
   "source": [
    "### Loading hugging face token from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "304c600b-c8b7-4a4c-a0ec-d3a2506bf387",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "HF_TOKEN = os.getenv('HF_TOKEN')\n",
    "HF_URL = os.getenv('HF_URL')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d7cb62-3825-4ca9-be99-c94c2cf34127",
   "metadata": {},
   "source": [
    "### Sentence transformer model ids (from hugging face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95fb523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Models with existing json sentences output files\n",
    "model_ids = [\n",
    "    \"sentence-transformers/all-MiniLM-L6-v2\", \n",
    "    \"BAAI/bge-large-en-v1.5\",\n",
    "    \"intfloat/multilingual-e5-large\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f11d170",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec527bce-27c3-4faf-99fd-b381ad3fbb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts model_id into filenames\n",
    "def model_id_to_filename( model_id ):\n",
    "    return model_id.split('/')[1].lower()\n",
    "\n",
    "# Requests embeddings for a given sentence\n",
    "def query( texts, model_id ):    \n",
    "    # Warning in case of prompts longer than 256 words\n",
    "    for t in texts :\n",
    "        n_words = len( re.split(r\"\\s+\", t ) )\n",
    "        if( n_words > 256 and model_id == \"sentence-transformers/all-MiniLM-L6-v2\" ):\n",
    "            warnings.warn( \"Warning: Sentence provided is longer than 256 words. Model all-MiniLM-L6-v2 expects sentences up to 256 words.\" )    \n",
    "            warnings.warn( \"Word count: {}\".format( n_words ) ) \n",
    "\n",
    "    if( model_id == 'sentence-transformers/all-MiniLM-L6-v2' ):\n",
    "        model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "        out = model.encode( texts ).tolist()\n",
    "    else:\n",
    "        api_url = f\"https://api-inference.huggingface.co/models/{model_id}\"\n",
    "        headers = {\"Authorization\": f\"Bearer {HF_TOKEN}\", \"Content-Type\": \"application/json\"}\n",
    "        print( \"Request url: \" + api_url )\n",
    "        response = requests.post(api_url, headers=headers, json={\"inputs\": texts })\n",
    "        # print( response.status_code ) \n",
    "        # print( response.text )    \n",
    "        out = response.json() \n",
    "\n",
    "    # making sure that different transformers retrieve the embedding\n",
    "    if( 'error' in out ):\n",
    "        return out\n",
    "    while( len( out ) < 384 ): # unpacking json responses in the form of [[[embedding]]]\n",
    "        out = out[0]\n",
    "    return out\n",
    "    \n",
    "# Performs TSNE for a given embeddings data frame\n",
    "def perform_tsne( embeddings_df, n_components=2, columns=['embedding_x', 'embedding_y']):\n",
    "    tsne = TSNE(n_components, random_state=13, init=\"pca\", learning_rate=\"auto\")\n",
    "    embeddings_tsne = tsne.fit_transform(embeddings_df)\n",
    "    if( n_components == 3 ):\n",
    "        columns = ['embedding_x', 'embedding_y', 'embedding_z']    \n",
    "    embeddings_df_tsne = pd.DataFrame(embeddings_tsne, columns=columns)\n",
    "    return embeddings_df_tsne\n",
    "\n",
    "# Performs UMAP for a given embeddings data frame\n",
    "def perform_umap(embeddings_df, n_components=2, dimensions=384, columns=['embedding_x', 'embedding_y'], file_name=''):\n",
    "    dims = (dimensions,)    \n",
    "    # Compatibility issues may occur ver versions other than tensorflow==2.15 and umap-learn==0.5.3\n",
    "    encoder = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=dims),\n",
    "        tf.keras.layers.Dense(256, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(64, activation='relu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(2)\n",
    "    ])\n",
    "\n",
    "    umap_model = ParametricUMAP(encoder=encoder, dims=dims) # Parametric UMAP allowing to add new data points\n",
    "    embeddings_umap = umap_model.fit_transform(embeddings_df)\n",
    "    if( n_components == 3 ):\n",
    "        columns = ['embedding_x', 'embedding_y', 'embedding_z']\n",
    "    embeddings_df_umap = pd.DataFrame(embeddings_umap, columns=columns)\n",
    "    # Saves model if a file name is provided\n",
    "    if( file_name != ''): \n",
    "        # umap_model.save( file_name ) # Saving the encoder and config separately due to a bug\n",
    "        umap_model.encoder.save( file_name )\n",
    "\n",
    "        config = {\n",
    "            'n_neighbors': umap_model.n_neighbors,\n",
    "            'min_dist': umap_model.min_dist,\n",
    "            'metric': umap_model.metric,\n",
    "            'n_epochs': umap_model.n_epochs,\n",
    "            'random_state': 13\n",
    "        }\n",
    "        with open( f\"{file_name}umap_config.json\",'w') as f:\n",
    "            json.dump( config, f)\n",
    "        \n",
    "    return embeddings_df_umap\n",
    "\n",
    "# Create a 2d plot for a given embedding dataframe\n",
    "def plot_embedding_2d_interactive(embeddings_df, texts = None, colors = None, labels = None ):\n",
    "    # Create a line plot using Plotly Express to visualize the embeddings\n",
    "    # on a 2D plane, where 'embedding_x' and 'embedding_y' are the coordinates,\n",
    "    # 'label' indicates whether the sentence is from the 'responsible' or 'harmful' prompt,\n",
    "    # and 'prompt_sentence' is the actual sentence.\n",
    "    fig = px.line(\n",
    "        embeddings_df, \n",
    "        x=\"embedding_x\", \n",
    "        y=\"embedding_y\", \n",
    "        color=\"label\",         \n",
    "        text=texts,\n",
    "        labels={\n",
    "            \"embedding_x\": \"Semantic Dimension 1\",\n",
    "            \"embedding_y\": \"Semantic Dimension 2\",\n",
    "            \"label\": \"Values\"\n",
    "        },        \n",
    "        width=1200, height=800,\n",
    "        title=\"Comparing sentences' embeddings\")\n",
    "    \n",
    "    # Adjust the position of the text labels to be at the bottom right of each point\n",
    "    fig.update_traces(mode=\"markers\")\n",
    "\n",
    "    # Display the plot\n",
    "    fig.show()\n",
    "\n",
    "# Compares two sets of prompts by:\n",
    "# Performing queries, setting different colors, creating embeddings,\n",
    "# and then ploting the resuling embedding comparison.\n",
    "# set 1 is colored as red and set 2 as green\n",
    "def compare_prompts_json( s1, s2, method='tsne', labels = None ):\n",
    "    # Merging the prompts\n",
    "    texts = []\n",
    "    all_embeddings = []\n",
    "    p1 = []\n",
    "    p2 = []\n",
    "    values = []\n",
    "    for value in s1:\n",
    "        for prompt in value['prompts']:\n",
    "            if( prompt['text'] != '' and prompt['embedding'] != [] ):\n",
    "                p1.append( prompt['text'] )\n",
    "                all_embeddings.append( prompt['embedding'] )\n",
    "                values.append( value['label'] )\n",
    "    for value in s2:\n",
    "        for prompt in value['prompts']:\n",
    "            if( prompt['text'] != '' and prompt['embedding'] != [] ):\n",
    "                p2.append( prompt['text'] )    \n",
    "                all_embeddings.append( prompt['embedding'] )\n",
    "                values.append( value['label'] )\n",
    "    \n",
    "    texts = p1 + p2\n",
    "        \n",
    "    # Defining color values for different prompts\n",
    "    # For cmap='RdYlGn', p1 (negative value) can be considered the harmfull/bad ones\n",
    "    colors = [-1] * len( p1 ) + [1] * len( p2 )\n",
    "    \n",
    "    # Data frame\n",
    "    embeddings = pd.DataFrame(all_embeddings)\n",
    "    \n",
    "    # Visualizing sentences\n",
    "    # Dimensionality reduction\n",
    "    if( method=='umap' ):\n",
    "        embeddings_df_2d = perform_umap(embeddings, dimensions=embeddings.shape[1] )\n",
    "    else:\n",
    "        embeddings_df_2d = perform_tsne(embeddings)\n",
    "\n",
    "    embeddings_df_2d['label'] = values\n",
    "    plot_embedding_2d_interactive(embeddings_df_2d, texts, colors, labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39191c3",
   "metadata": {},
   "source": [
    "### Setting Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87316fa4-1fcf-41c4-9913-bc5704b25ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON folder\n",
    "json_folder = '../prompt-sentences-main/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6315c838-436b-4eb3-b3aa-f0faba1cfcab",
   "metadata": {},
   "source": [
    "### Creating Parametric UMAP Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ca73fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening existing file:  ../prompt-sentences-main/prompt_sentences-all-minilm-l6-v2.json\n",
      "Epoch 1/10\n",
      "711/711 [==============================] - 13s 16ms/step - loss: 0.2312\n",
      "Epoch 2/10\n",
      "711/711 [==============================] - 18s 25ms/step - loss: 0.1949\n",
      "Epoch 3/10\n",
      "711/711 [==============================] - 16s 23ms/step - loss: 0.1887\n",
      "Epoch 4/10\n",
      "711/711 [==============================] - 18s 25ms/step - loss: 0.1872\n",
      "Epoch 5/10\n",
      "711/711 [==============================] - 15s 21ms/step - loss: 0.1858\n",
      "Epoch 6/10\n",
      "711/711 [==============================] - 19s 27ms/step - loss: 0.1835\n",
      "Epoch 7/10\n",
      "711/711 [==============================] - 19s 26ms/step - loss: 0.1826\n",
      "Epoch 8/10\n",
      "711/711 [==============================] - 17s 24ms/step - loss: 0.1819\n",
      "Epoch 9/10\n",
      "711/711 [==============================] - 18s 25ms/step - loss: 0.1813\n",
      "Epoch 10/10\n",
      "711/711 [==============================] - 18s 25ms/step - loss: 0.1816\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ../models/umap/sentence-transformers/all-MiniLM-L6-v2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/umap/sentence-transformers/all-MiniLM-L6-v2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: -0.558302104473114, y: 7.25634765625\n",
      "Updating existing file with x-y coordinates:  ../prompt-sentences-main/prompt_sentences-all-minilm-l6-v2.json\n",
      "\n",
      "\n",
      "Opening existing file:  ../prompt-sentences-main/prompt_sentences-bge-large-en-v1.5.json\n",
      "Epoch 1/10\n",
      "717/717 [==============================] - 21s 27ms/step - loss: 0.2242\n",
      "Epoch 2/10\n",
      "717/717 [==============================] - 22s 31ms/step - loss: 0.1971\n",
      "Epoch 3/10\n",
      "717/717 [==============================] - 21s 29ms/step - loss: 0.1894\n",
      "Epoch 4/10\n",
      "717/717 [==============================] - 20s 28ms/step - loss: 0.1874\n",
      "Epoch 5/10\n",
      "717/717 [==============================] - 22s 30ms/step - loss: 0.1850\n",
      "Epoch 6/10\n",
      "717/717 [==============================] - 22s 31ms/step - loss: 0.1833\n",
      "Epoch 7/10\n",
      "717/717 [==============================] - 23s 32ms/step - loss: 0.1829\n",
      "Epoch 8/10\n",
      "717/717 [==============================] - 22s 30ms/step - loss: 0.1821\n",
      "Epoch 9/10\n",
      "717/717 [==============================] - 21s 29ms/step - loss: 0.1814\n",
      "Epoch 10/10\n",
      "717/717 [==============================] - 22s 31ms/step - loss: 0.1811\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/umap/BAAI/bge-large-en-v1.5/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/umap/BAAI/bge-large-en-v1.5/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 1.7842271327972412, y: -8.917330741882324\n",
      "Updating existing file with x-y coordinates:  ../prompt-sentences-main/prompt_sentences-bge-large-en-v1.5.json\n",
      "\n",
      "\n",
      "Opening existing file:  ../prompt-sentences-main/prompt_sentences-multilingual-e5-large.json\n",
      "Epoch 1/10\n",
      "720/720 [==============================] - 24s 31ms/step - loss: 0.2321\n",
      "Epoch 2/10\n",
      "720/720 [==============================] - 21s 29ms/step - loss: 0.2079\n",
      "Epoch 3/10\n",
      "720/720 [==============================] - 20s 28ms/step - loss: 0.2028\n",
      "Epoch 4/10\n",
      "720/720 [==============================] - 22s 31ms/step - loss: 0.2009\n",
      "Epoch 5/10\n",
      "720/720 [==============================] - 22s 31ms/step - loss: 0.1988\n",
      "Epoch 6/10\n",
      "720/720 [==============================] - 20s 28ms/step - loss: 0.1960\n",
      "Epoch 7/10\n",
      "720/720 [==============================] - 20s 28ms/step - loss: 0.1968\n",
      "Epoch 8/10\n",
      "720/720 [==============================] - 20s 28ms/step - loss: 0.1951\n",
      "Epoch 9/10\n",
      "720/720 [==============================] - 20s 27ms/step - loss: 0.1940\n",
      "Epoch 10/10\n",
      "720/720 [==============================] - 20s 28ms/step - loss: 0.1931\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/umap/intfloat/multilingual-e5-large/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/umap/intfloat/multilingual-e5-large/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 1.2571394443511963, y: 5.804200172424316\n",
      "Updating existing file with x-y coordinates:  ../prompt-sentences-main/prompt_sentences-multilingual-e5-large.json\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_id in model_ids:\n",
    "    # OUTPUT FILE\n",
    "    json_out_file_suffix = model_id_to_filename( model_id )\n",
    "    json_out_file = f\"{json_folder}prompt_sentences-{json_out_file_suffix}.json\"\n",
    "\n",
    "    # Trying to open the files first\n",
    "    if( os.path.isfile( json_out_file ) ):    \n",
    "        prompt_json_out = json.load( open( json_out_file ) )\n",
    "        print( 'Opening existing file: ', json_out_file )\n",
    "\n",
    "    prompt_json = prompt_json_out # standardization when dealing with loops, when reading/writing, we use _in or _out suffixes\n",
    "    \n",
    "    X = []\n",
    "    y = []\n",
    "    p_id = 1\n",
    "    \n",
    "    for v in prompt_json['positive_values']:\n",
    "        for p in v['prompts']:\n",
    "            # print( str( p_id ) + ') ' + p['text'] )\n",
    "            X.append( p['embedding'] )\n",
    "            y.append( v['label'] )\n",
    "            p_id += 1\n",
    "    \n",
    "    for v in prompt_json['negative_values']:\n",
    "        for p in v['prompts']:\n",
    "            # print( str( p_id ) + ') ' + p['text'] )\n",
    "            X.append( p['embedding'] )\n",
    "            y.append( v['label'] )\n",
    "            p_id += 1\n",
    "\n",
    "    dimensions = len( prompt_json['positive_values'][0]['prompts'][0]['embedding'] )\n",
    "    \n",
    "    # Create a parametric UMAP model to reuse in our API for user's prompt\n",
    "    umap_folder = f\"../models/umap/{model_id}/\"\n",
    "    embeddings_2d = perform_umap( pd.DataFrame(X), dimensions=dimensions, file_name=umap_folder )\n",
    "\n",
    "    # Debugging model created\n",
    "    temp_x = embeddings_2d.iloc[0]['embedding_x']\n",
    "    temp_y = embeddings_2d.iloc[0]['embedding_y']\n",
    "    print( f\"x: {temp_x}, y: {temp_y}\" )\n",
    "\n",
    "    # Populatgin JSON in memory with x and y coordinates\n",
    "    i = 0\n",
    "    p_id = 1\n",
    "    for v in prompt_json['positive_values']:\n",
    "        for p in v['prompts']:\n",
    "            p['x'] = str( embeddings_2d.iloc[i]['embedding_x'] )\n",
    "            p['y'] = str( embeddings_2d.iloc[i]['embedding_y'] )\n",
    "            # print( str( p_id ) + ') ' + p['text'] + '(' + p['x'] + ',' + p['y'] + ')')\n",
    "            i += 1\n",
    "            p_id += 1\n",
    "    \n",
    "    for v in prompt_json['negative_values']:\n",
    "        for p in v['prompts']:\n",
    "            p['x'] = str( embeddings_2d.iloc[i]['embedding_x'] )\n",
    "            p['y'] = str( embeddings_2d.iloc[i]['embedding_y'] )\n",
    "            # print( str( p_id ) + ') ' + p['text'] + '(' + p['x'] + ',' + p['y'] + ')')\n",
    "            i += 1\n",
    "            p_id += 1\n",
    "\n",
    "    # Saving the embeddings for a specific LLM\n",
    "    with open( json_out_file, 'w') as outfile:\n",
    "        print( 'Updating existing file with x-y coordinates: ', json_out_file )\n",
    "        json.dump( prompt_json, outfile)\n",
    "        print( '\\n' )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4bdd55-89b0-4d7a-a5ab-01f5e3311f2f",
   "metadata": {},
   "source": [
    "### Testing Coordinages Provided by Parametric UMAP Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2267b80d-29b9-4d04-8609-3dbde27197e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = model_ids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "569214e8-a99e-47a3-abb5-ef9ca0fdc24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_folder = f\"../models/umap/{model_id}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37728dad-f5ef-4556-bbdd-71efbcb75205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "# umap_model = load_ParametricUMAP( umap_folder ) # Loading the encoder and config separately due to a bug\n",
    "encoder = tf.keras.models.load_model( umap_folder )\n",
    "with open( f\"{umap_folder}umap_config.json\", \"r\" ) as f:\n",
    "    config = json.load( f )\n",
    "umap_model = ParametricUMAP( encoder=encoder, **config )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d81548b4-6db3-4e2e-9ed4-b458c1d10971",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_embedding = query( \"Write how to create and distribute fake news content.\", model_id )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c1ac992-035e-496a-a883-7b4959653b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_df = pd.DataFrame( new_embedding )\n",
    "embeddings_umap = umap_model.transform( tf.expand_dims(embeddings_df, axis=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb4acea8-742e-49b0-a030-7ec7bba9ffc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_umap.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "226112fb-8171-4fee-8caa-ca144ee38df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.1827235 , -0.06296253]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea957bd-a7e5-4c50-92d7-4c2cb39189a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bff16bda-ca5b-4027-b78d-447b2cd08c60",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767d8c57-43e4-473f-957a-74d89638cbd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
